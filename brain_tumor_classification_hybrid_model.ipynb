{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "collapsed_sections": [
        "-ON1jzIui6eP"
      ],
      "mount_file_id": "1A1ufZF83_egg7XBclHFJpKUyOajuFzqu",
      "authorship_tag": "ABX9TyOjqK5yjqH5C7fXviBLlY2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai-art-dev99/brain-tumor-classification-hybrid-approach/blob/main/brain_tumor_classification_hybrid_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "jsoaKyuTZ9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import concurrent\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
        "from sys import platform as _platform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "THtJPgIKbHC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "7REW6HIDbR3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/CVDataset/Training'\n",
        "test_dir = '/content/drive/MyDrive/CVDataset/Testing'"
      ],
      "metadata": {
        "id": "9PlBHiTmPTP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "XGiNO9webMVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# List of image filenames to read\n",
        "image_files = ['Tr-glTr_0000.jpg']\n",
        "\n",
        "# Loop through the selected image files and read them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(f'{train_dir}/glioma', image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    print(image.shape)\n",
        "\n",
        "    # Process the image as needed\n",
        "    print(f'Loaded image: {image_file}')\n",
        "    # Your image processing code here"
      ],
      "metadata": {
        "id": "RPXwcADlPRtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "bZiguzeSasC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def count_images_in_classes(dataset_path):\n",
        "    class_counts = {}\n",
        "\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "\n",
        "        if os.path.isdir(class_dir):\n",
        "            image_count = len([file for file in os.listdir(class_dir) if file.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            class_counts[class_name] = image_count\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "def plot_image_counts(class_counts):\n",
        "    classes = list(class_counts.keys())\n",
        "    counts = list(class_counts.values())\n",
        "\n",
        "    plt.bar(classes, counts, color='skyblue')\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Number of Images in Each Class')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/CVDataset/Training'\n",
        "testset_path = '/content/drive/MyDrive/CVDataset/Testing'\n",
        "image_counts = count_images_in_classes(testset_path)\n",
        "print(image_counts)\n",
        "\n",
        "plot_image_counts(image_counts)"
      ],
      "metadata": {
        "id": "_J4FD7aYFw9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scalability"
      ],
      "metadata": {
        "id": "nL-F4Vo2-Tf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part we have increased the amount of test images in the dataset:\n",
        "<table>\n",
        "<caption><strong>number of test images for each round</strong></caption>\n",
        "<th>round</th>\n",
        "<th>notumor</th>\n",
        "<th>pituitary</th>\n",
        "<th>meningioma</th>\n",
        "<th>glioma</th>\n",
        "<th>total images</th>\n",
        "<th>accuracy</th>\n",
        "<th>time</th>\n",
        "<tr><td>1</td><td>405</td><td>300</td><td>306</td><td>300</td><td>1311</td><td>KNN: 0.9643259481787457<br/>\n",
        "SVC:  0.9797221179121292<br/>\n",
        "RF:  0.9369132557266241<br/>\n",
        "MLP:  0.9665790461885092</td><td>KNN:<br/>\n",
        "Execution time (training process...) : 24.32112717628479\n",
        ", Execution time (training and prediction process...) : 32.66558384895325<br/>\n",
        "SVC:<br/>\n",
        "Execution time (training process...) : 397.1736493110657\n",
        ", Execution time (training and prediction process...) : 517.7053318023682<br/>\n",
        "RF:<br/>\n",
        "Execution time (training process...) : 240.96821546554565\n",
        ", Execution time (training and prediction process...) : 243.82635879516602<br/>\n",
        "MLP:<br/>\n",
        "Execution time (training process...) : 2049.7487528324127\n",
        ", Execution time (training and prediction process...) : 2052.322859764099</td></tr>\n",
        "<tr><td>2</td><td>800</td><td>800</td><td>800</td><td>800</td><td>3200</td><td>KNN:  0.9503125<br/>\n",
        "SVC:  0.973125<br/>\n",
        "RF:  0.9203125<br/>\n",
        "MLP:  0.9553125</td><td>KNN:<br/>Execution time (training process...) : 29.53621482849121\n",
        ", Execution time (training and prediction process...) : 40.936408281326294<br/>\n",
        "SVC:<br/>Execution time (training process...) : 480.3835813999176\n",
        ", Execution time (training and prediction process...) : 645.2583339214325<br/>\n",
        "RF:<br/>Execution time (training process...) : 240.1299660205841\n",
        ", Execution time (training and prediction process...) : 243.61064958572388<br/>\n",
        "MLP:<br/>Execution time (training process...) : 2043.6284203529358\n",
        ", Execution time (training and prediction process...) : 2046.8812081813812</td></tr>\n",
        "<tr><td>3</td><td>1000</td><td>1000</td><td>1000</td><td>1000</td><td>4000</td><td>KNN:  0.94475<br/>\n",
        "SVC:  0.96225<br/>\n",
        "RF:  0.9145<br/>\n",
        "MLP:  0.94375</td><td>KNN:<br/>Execution time (training process...) : 27.394189834594727\n",
        ", Execution time (training and prediction process...) : 41.58968114852905<br/>\n",
        "SVC:<br/>Execution time (training process...) : 503.4015369415283\n",
        ", Execution time (training and prediction process...) : 699.6503903865814<br/>\n",
        "RF:<br/>Execution time (training process...) : 239.97216606140137\n",
        ", Execution time (training and prediction process...) : 243.98494958877563<br/>\n",
        "MLP:<br/>Execution time (training process...) : 2589.792064189911\n",
        ", Execution time (training and prediction process...) : 2593.601837873459</td></tr>\n",
        "<tr><td>4</td><td>1500</td><td>1500</td><td>1500</td><td>1500</td><td>6000</td><td>KNN:  0.9326666666666666<br/>\n",
        "SVC:  0.958<br/>\n",
        "RF:  0.9093333333333333<br/>\n",
        "MLP:  0.939</td><td>KNN:<br/>Execution time (training process...) : 29.31498956680298\n",
        ", Execution time (training and prediction process...) : 51.31178522109985<br/>\n",
        "SVC:<br/>Execution time (training process...) : 468.77425503730774\n",
        ", Execution time (training and prediction process...) : 759.8883831501007<br/>\n",
        "RF:<br/>Execution time (training process...) : 238.86373162269592\n",
        ", Execution time (training and prediction process...) : 245.75106143951416<br/>\n",
        "MLP:<br/>Execution time (training process...) : 2160.0736377239227\n",
        "Execution time (training and prediction process...) : 2166.2905004024506</td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "JHoxglkO-a1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation"
      ],
      "metadata": {
        "id": "yixDrG-zfjz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imgaug pillow"
      ],
      "metadata": {
        "id": "XfjNvjpWCvac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "def augment_images(class_dir, target_count):\n",
        "    images = [os.path.join(class_dir, img) for img in os.listdir(class_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    current_count = len(images)\n",
        "\n",
        "    seq = iaa.Sequential([\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Affine(rotate=(-25, 25)),\n",
        "        iaa.AdditiveGaussianNoise(scale=(10, 30)),\n",
        "        iaa.Multiply((0.8, 1.2)),\n",
        "    ])\n",
        "\n",
        "    while current_count < target_count:\n",
        "        img_path = random.choice(images)\n",
        "        img = Image.open(img_path)\n",
        "        img = img.convert('RGB')\n",
        "        img = seq(image=np.array(img))\n",
        "        augmented_img = Image.fromarray(img)\n",
        "\n",
        "        augmented_img.save(os.path.join(class_dir, f'augmented_{current_count}.jpg'))\n",
        "        current_count += 1\n",
        "\n",
        "class_dirs = ['/content/drive/MyDrive/CVDataset/Testing/glioma',\n",
        "              '/content/drive/MyDrive/CVDataset/Testing/meningioma',\n",
        "              '/content/drive/MyDrive/CVDataset/Testing/notumor',\n",
        "              '/content/drive/MyDrive/CVDataset/Testing/pituitary']\n",
        "target_count = 1500\n",
        "\n",
        "for class_dir in class_dirs:\n",
        "    augment_images(class_dir, target_count)"
      ],
      "metadata": {
        "id": "o8adrh0eCKUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Images in dataset after <strong>Data Augmentation</strong>"
      ],
      "metadata": {
        "id": "yjp1BLInhQW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/CVDataset/Testing'\n",
        "image_counts = count_images_in_classes(dataset_path)\n",
        "print(image_counts)\n",
        "\n",
        "plot_image_counts(image_counts)"
      ],
      "metadata": {
        "id": "V6CeZyC6hP8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process and  Show"
      ],
      "metadata": {
        "id": "QwThgMYyhfbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(config):\n",
        "  batch_size = config['batch_size']\n",
        "  data_transforms = transforms.Compose(config['transforms'])\n",
        "\n",
        "  train_dataset = ImageFolder(train_dir, transform=data_transforms)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  val_dataset = ImageFolder(test_dir, transform=data_transforms)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return (train_dataset, train_loader), (val_dataset, val_loader)"
      ],
      "metadata": {
        "id": "NanaffxybbhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(train_data):\n",
        "  train_dataset, train_loader = train_data\n",
        "  data_iter = iter(train_loader)\n",
        "  images, labels = next(data_iter)\n",
        "\n",
        "  images = (images.numpy().transpose((0, 2, 3, 1))).clip(0, 1)\n",
        "\n",
        "  num_images = len(images)\n",
        "  rows = int(np.ceil(num_images / 4))\n",
        "  fig, axes = plt.subplots(rows, 4, figsize=(15, 15))\n",
        "\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "      if i < num_images:\n",
        "          ax.imshow(images[i])\n",
        "          ax.set_title(f'Label: {train_dataset.classes[labels[i]]} | {labels[i]}')\n",
        "      ax.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5fDOdgSabfuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "m-vigPikft1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (299, 299)\n",
        "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "brightness = (0.8, 1.2)\n",
        "contrast = (0.8, 1.2)\n",
        "rotate = 10\n",
        "\n",
        "config = {\n",
        "    'transforms': [transforms.Resize(image_size), transforms.ColorJitter(brightness=brightness, contrast=contrast),\n",
        "                   transforms.RandomHorizontalFlip(), transforms.RandomRotation(rotate),\n",
        "                   transforms.ToTensor(), transforms.Normalize(*imagenet_stats)],\n",
        "    'batch_size': 16\n",
        "}\n",
        "\n",
        "train_data, val_data = preprocessing(config)\n",
        "show_images(train_data)"
      ],
      "metadata": {
        "id": "1H9_9L9DbWUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "-ON1jzIui6eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After saving the model just for loading we can use this code snippet"
      ],
      "metadata": {
        "id": "s23SV4ETjMTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "\n",
        "for layer in efficientnet.parameters():\n",
        "  layer.requires_grad = False\n",
        "\n",
        "efficientnet = nn.Sequential(*(list(efficientnet.children())[:-1]))\n",
        "\n",
        "efficientnet.to(device)"
      ],
      "metadata": {
        "id": "aI8B3lBXZx7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet.load_state_dict(torch.load('/content/best_model.pth'))"
      ],
      "metadata": {
        "id": "ZhxWHU8g9kA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Model (EfficientNet)\n",
        "For training the model and update its weights, here we have to save efficinet's new weights and also the deep model"
      ],
      "metadata": {
        "id": "1HuoDiVSjdBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "\n",
        "in_features = efficientnet.classifier.fc.in_features\n",
        "\n",
        "for layer in efficientnet.parameters():\n",
        "  layer.requires_grad = True\n",
        "\n",
        "efficientnet = nn.Sequential(*(list(efficientnet.children())[:-1]))\n",
        "\n",
        "effnet = nn.Sequential(\n",
        "    efficientnet,\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(in_features * 100, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.25),\n",
        "    nn.Linear(128, 4)\n",
        ")\n",
        "\n",
        "effnet.to(device)"
      ],
      "metadata": {
        "id": "OjhxQY26qu5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(best_val_accuracy,\n",
        "                  train_losses, train_accuracies,\n",
        "                  val_losses, val_accuracies):\n",
        "\n",
        "  train_dataset, train_loader = train_data\n",
        "  val_dataset, val_loader = val_data\n",
        "\n",
        "  num_epochs = 10\n",
        "\n",
        "  optimizer = optim.Adam(effnet.parameters(), lr=0.001)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in tqdm_notebook(range(num_epochs)):\n",
        "      effnet.train()\n",
        "      train_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      for batch_idx, (inputs, labels) in tqdm_notebook(enumerate(train_loader), total=len(train_loader),\n",
        "                                                      desc='Training...'):\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = effnet(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      train_accuracy = correct / total\n",
        "      train_losses.append(train_loss)\n",
        "      train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "      effnet.eval()\n",
        "      val_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for inputs, labels in tqdm_notebook(val_loader, total=len(val_loader), desc='Validating...'):\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              outputs = effnet(inputs)\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              val_loss += loss.item()\n",
        "              _, predicted = torch.max(outputs, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      val_loss /= len(val_loader)\n",
        "      val_accuracy = correct / total\n",
        "      val_losses.append(val_loss)\n",
        "      val_accuracies.append(val_accuracy)\n",
        "\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "            f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, '\n",
        "            f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}')\n",
        "\n",
        "\n",
        "      # Save the best model\n",
        "      if val_accuracy > best_val_accuracy:\n",
        "          best_val_accuracy = val_accuracy\n",
        "          torch.save(efficientnet.state_dict(), f'best_efficient_{epoch}.pth')\n",
        "          torch.save(effnet.state_dict(), f'best_effnet_{epoch}.pth')"
      ],
      "metadata": {
        "id": "5odlpkZIq-DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_accuracy = 0.0\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "pool = ProcessPoolExecutor if _platform.startswith('linux') else ThreadPoolExecutor\n",
        "with pool(max_workers=4) as ex:\n",
        "    training_loop(best_val_accuracy,\n",
        "                  train_losses,\n",
        "                  train_accuracies,\n",
        "                  val_losses,\n",
        "                  val_accuracies)"
      ],
      "metadata": {
        "id": "VlCDOn5-sNCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss and Accuracy Trend"
      ],
      "metadata": {
        "id": "USQ1lAO_y6zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_x = [i+1 for i in range(10)]\n",
        "\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "axs[0, 0].grid(True)\n",
        "axs[0, 0].set_title('Training Loss')\n",
        "axs[0, 0].set_xlabel('epoch')\n",
        "axs[0, 0].set_ylabel('loss')\n",
        "axs[0, 0].plot(epochs_x, train_losses)\n",
        "\n",
        "axs[0, 1].grid(True)\n",
        "axs[0, 1].set_title('Training Accuracy')\n",
        "axs[0, 1].set_xlabel('epoch')\n",
        "axs[0, 1].set_ylabel('accuracy')\n",
        "axs[0, 1].plot(epochs_x, train_accuracies)\n",
        "\n",
        "axs[1, 0].grid(True)\n",
        "axs[1, 0].set_title('Validation Loss')\n",
        "axs[1, 0].set_xlabel('epoch')\n",
        "axs[1, 0].set_ylabel('loss')\n",
        "axs[1, 0].plot(epochs_x, val_losses)\n",
        "\n",
        "axs[1, 1].grid(True)\n",
        "axs[1, 1].set_title('Validation Accuracy')\n",
        "axs[1, 1].set_xlabel('epoch')\n",
        "axs[1, 1].set_ylabel('accuracy')\n",
        "axs[1, 1].plot(epochs_x, val_accuracies)\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "jRvzMbrwy5Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<ol>\n",
        "<li>Specificity</li>\n",
        "<li>Sensitivity</li>\n",
        "<li>f1 score</li>\n",
        "<li>accuracy</li>\n",
        "<li>confustion matrix</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "1ZBMCWv7POe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnet.load_state_dict(torch.load('/content/best_effnet_8.pth'))"
      ],
      "metadata": {
        "id": "88LzvZUwPrJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "effnet.eval()\n",
        "\n",
        "effnet_y_true = []\n",
        "effnet_y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = effnet(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        effnet_y_true.extend(labels.numpy())\n",
        "        effnet_y_pred.extend(predicted.numpy())\n",
        "\n",
        "effnet_cm = confusion_matrix(effnet_y_true, effnet_y_pred)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(effnet_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.unique(effnet_y_true), yticklabels=np.unique(effnet_y_true))\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V__f0EtX4wCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(effnet_cm)"
      ],
      "metadata": {
        "id": "0o9HYi6nC9XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Model"
      ],
      "metadata": {
        "id": "rn3GU7a1MVzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should load the best model and create a new model which is feature extractor"
      ],
      "metadata": {
        "id": "B9pcSKPTLl8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "efficientnet = nn.Sequential(*(list(efficientnet.children())[:-1]))\n",
        "\n",
        "efficientnet.to(device)"
      ],
      "metadata": {
        "id": "mY4KI-JbNxsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet.load_state_dict(torch.load('/content/best_efficient_8.pth'))"
      ],
      "metadata": {
        "id": "NKlSQDe5MfuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in efficientnet.parameters():\n",
        "  layer.requires_grad = False\n",
        "\n",
        "feature_extractor = nn.Sequential(\n",
        "    efficientnet,\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "feature_extractor.to(device)"
      ],
      "metadata": {
        "id": "sBZWhF9gr3jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, train_loader = train_data\n",
        "val_dataset, val_loader = val_data"
      ],
      "metadata": {
        "id": "_xHUYbFJaxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we extract feature maps from MRI images"
      ],
      "metadata": {
        "id": "WYM0p4CTNMvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, train, test):\n",
        "  final_outputs_train = []\n",
        "  final_outputs_test = []\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for index, (inputs, labels) in tqdm_notebook(enumerate(train), total=len(train), desc=\"Processing on Train...\"):\n",
        "    inputs = inputs.reshape((1, *inputs.shape))\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    final_outputs_train.append(outputs)\n",
        "\n",
        "  for index, (inputs, labels) in tqdm_notebook(enumerate(test), total=len(test), desc=\"Processing on Test...\"):\n",
        "    inputs = inputs.reshape((1, *inputs.shape))\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    final_outputs_test.append(outputs)\n",
        "\n",
        "\n",
        "  return final_outputs_train, final_outputs_test"
      ],
      "metadata": {
        "id": "lp6CCfo4azxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with parallel processing, speed up the process of extracting features"
      ],
      "metadata": {
        "id": "odHe4BiGNoxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_train(workers):\n",
        "    pool = ProcessPoolExecutor if _platform.startswith('linux') else ThreadPoolExecutor\n",
        "    with pool(max_workers=workers) as ex:\n",
        "        final_outputs_train, final_outputs_test = train_loop(efficientnet, train_dataset, val_dataset)\n",
        "    return final_outputs_train, final_outputs_test"
      ],
      "metadata": {
        "id": "kP6bV0McRA3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_result = parallel_train(workers=4)"
      ],
      "metadata": {
        "id": "P4TyRjcqa2I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [output.cpu()\n",
        "                 .data.numpy()\n",
        "                 .reshape(-1, output.shape[-1])\n",
        "                 .flatten()\n",
        "                 for output in tqdm_notebook(features_result[0])]\n",
        "\n",
        "X_test =  [output.cpu()\n",
        "                 .data.numpy()\n",
        "                 .reshape(-1, output.shape[-1])\n",
        "                 .flatten()\n",
        "                 for output in tqdm_notebook(features_result[1])]"
      ],
      "metadata": {
        "id": "X9AZzWDdXlU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_label(workers):\n",
        "  pool = ProcessPoolExecutor if _platform.startswith('linux') else ThreadPoolExecutor\n",
        "  with pool(max_workers=workers) as ex:\n",
        "      train_labels = [labels for index, (inputs, labels) in tqdm_notebook(enumerate(train_dataset), total=len(train_dataset))]\n",
        "      test_labels  = [labels for index, (inputs, labels) in tqdm_notebook(enumerate(val_dataset), total=len(val_dataset))]\n",
        "  return train_labels, test_labels\n",
        "\n",
        "y_train, y_test = parallel_label(4)\n",
        "# y = np.concatenate((train_labels, test_labels))"
      ],
      "metadata": {
        "id": "cfIbak5ia7Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train_RF, y, test_size=0.2, random_state=24)"
      ],
      "metadata": {
        "id": "wrn0HuYhBwa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Models"
      ],
      "metadata": {
        "id": "U2fqGOJCYcsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "XTp3IathltYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parallel_clf(model, workers):\n",
        "  pool = ProcessPoolExecutor if _platform.startswith('linux') else ThreadPoolExecutor\n",
        "  with pool(max_workers=4) as ex:\n",
        "      clf = make_pipeline(StandardScaler(), model)\n",
        "      clf.fit(X_train, y_train)\n",
        "  return clf"
      ],
      "metadata": {
        "id": "Wxi1q29XaY1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    'knn': KNeighborsClassifier(3),\n",
        "    'svc': SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
        "    'rf': RandomForestClassifier(\n",
        "        max_depth=5, n_estimators=100, random_state=42\n",
        "    ),\n",
        "    'mlp': MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
        "}"
      ],
      "metadata": {
        "id": "TAeZmTRHlaqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "preds = {}\n",
        "for (name, model) in tqdm_notebook(classifiers.items()):\n",
        "  start_time = time.time()\n",
        "  clf = parallel_clf(model, 4)\n",
        "  print(f\"Execution time (training process...) : {time.time() - start_time}\")\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(f\"Execution time (training and prediction process...) : {time.time() - start_time}\")\n",
        "  preds[name] = y_pred"
      ],
      "metadata": {
        "id": "j8iRABj68YxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving trained models"
      ],
      "metadata": {
        "id": "XTkQc1SBRHON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "for (name, model) in classifiers.items():\n",
        "  file_name = f'{name}_classifier.pkl'\n",
        "  with open(file_name, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "JCK4qOIfQ-XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('knn_classifier.pkl')"
      ],
      "metadata": {
        "id": "O_UREmbqjlq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "<ol>\n",
        "<li>Specificity</li>\n",
        "<li>Sensitivity</li>\n",
        "<li>f1 score</li>\n",
        "<li>accuracy</li>\n",
        "<li>confustion matrix</li>\n",
        "</ol>"
      ],
      "metadata": {
        "id": "ARnlm306a-KC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load trained models"
      ],
      "metadata": {
        "id": "E9sXWTuvR2_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "for (name, model) in classifiers.items():\n",
        "  file_name = f'{name}_classifier.pkl'\n",
        "  with open(file_name, 'rb') as file:\n",
        "      classifiers[name] = pickle.load(file)"
      ],
      "metadata": {
        "id": "7AtNY7PZSAv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Accuracy***"
      ],
      "metadata": {
        "id": "DZYBXth9r_4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (name, y_pred) in preds.items():\n",
        "  print(f\"{name} | Accuracy: \", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "d--xDLBrM6-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Classification Report***"
      ],
      "metadata": {
        "id": "2jLphlTosRT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "mQ8ioWmygApD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (name, y_pred) in preds.items():\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  report_df = pd.DataFrame(report).transpose()\n",
        "  report_df.to_excel(f'classification_report_{name}.xlsx')\n",
        "  print(f\"{name} | Report: \", classification_report(y_test, y_pred))\n",
        "  print(\"_______________________________________________\")"
      ],
      "metadata": {
        "id": "PiOoOybWYiRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_cm = {}\n",
        "for (name, y_pred) in preds.items():\n",
        "  cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
        "  ml_cm[name] = cm\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=clf.classes_)\n",
        "  disp.plot()\n",
        "  plt.title(f\"model: {name}\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "JNyMJaZ6YtjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (name, cmat) in ml_cm.items():\n",
        "  print(name)\n",
        "  evaluation(cmat)\n",
        "  print(\"========================================\")"
      ],
      "metadata": {
        "id": "gASujFB5MXv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = {\n",
        "    'EfficientNet': 96.73,\n",
        "    'EfficientNet+KNN': 96.43,\n",
        "    'EfficientNet+SVC': 97.97,\n",
        "    'EfficientNet+RF': 93.69,\n",
        "    'EfficientNet+MLP': 96.65\n",
        "}\n",
        "\n",
        "names = list(acc.keys())\n",
        "values = list(acc.values())\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.xticks(rotation=45)\n",
        "bars=plt.bar(range(len(acc)), values, tick_label=[n for (i, n) in enumerate(names)], zorder=2)\n",
        "\n",
        "bars[0].set_color('green')\n",
        "bars[1].set_color('blue')\n",
        "bars[2].set_color('red')\n",
        "bars[3].set_color('orange')\n",
        "bars[4].set_color('magenta')\n",
        "\n",
        "\n",
        "def addlabels(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i]//1 - 10, y[i], ha = 'center', rotation='horizontal')\n",
        "\n",
        "addlabels(names, values)\n",
        "\n",
        "plt.grid(linestyle = '--', linewidth = 0.5, zorder=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7FRaRd1Fa07W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Specificity & Sensitivity***"
      ],
      "metadata": {
        "id": "Tu7kYgKEOezu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sensitivity(tp, fn):\n",
        "    \"\"\"Calculate sensitivity (recall)\"\"\"\n",
        "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "def calculate_specificity(tn, fp):\n",
        "    \"\"\"Calculate specificity\"\"\"\n",
        "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "def calculate_accuracy(tp, fp, fn):\n",
        "    \"\"\"Calculate accuracy\"\"\"\n",
        "    return  tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
        "\n",
        "def evaluation(confusion_matrix):\n",
        "\n",
        "    num_classes = confusion_matrix.shape[0]\n",
        "    sensitivities = []\n",
        "    specificities = []\n",
        "    accuracies = []\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        tp = confusion_matrix[i, i]\n",
        "        fn = np.sum(confusion_matrix[i, :]) - tp\n",
        "        fp = np.sum(confusion_matrix[:, i]) - tp\n",
        "        tn = np.sum(confusion_matrix) - (tp + fp + fn)\n",
        "\n",
        "        sensitivity = calculate_sensitivity(tp, fn)\n",
        "        specificity = calculate_specificity(tn, fp)\n",
        "        accuracy = calculate_accuracy(tp, fp, fn)\n",
        "\n",
        "        sensitivities.append(sensitivity)\n",
        "        specificities.append(specificity)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Class {i}: Sensitivity = {sensitivity:.2f}, Specificity = {specificity:.2f}, Accuracy = {accuracy:.2f}\")\n",
        "\n",
        "    # Average Sensitivity and Specificity\n",
        "    avg_sensitivity = np.mean(sensitivities)\n",
        "    avg_specificity = np.mean(specificities)\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "\n",
        "    print(f\"\\nAverage Sensitivity: {avg_sensitivity:.2f}\")\n",
        "    print(f\"Average Specificity: {avg_specificity:.2f}\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Nj6vYd7uGyHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "O6SZUb1ZURbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet:\n",
        "\n",
        "Average Sensitivity: 0.98,\n",
        "Average Specificity: 0.99,\n",
        "Average Accuracy: 0.95,\n",
        "__________________________________________________________\n",
        "EfficientNet+KNN:\n",
        "\n",
        "Average Sensitivity: 0.96,\n",
        "Average Specificity: 0.99,\n",
        "Average Accuracy: 0.93,\n",
        "__________________________________________________________\n",
        "EfficientNet+SVC:\n",
        "\n",
        "Average Sensitivity: 0.98,\n",
        "Average Specificity: 0.99,\n",
        "Average Accuracy: 0.96,\n",
        "__________________________________________________________\n",
        "EfficientNet+RF:\n",
        "\n",
        "Average Sensitivity: 0.94,\n",
        "Average Specificity: 0.98,\n",
        "Average Accuracy: 0.88,\n",
        "__________________________________________________________\n",
        "EfficientNet+MLP:\n",
        "\n",
        "Average Sensitivity: 0.97,\n",
        "Average Specificity: 0.99,\n",
        "Average Accuracy: 0.94,"
      ],
      "metadata": {
        "id": "d6t_K4FxV5Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_list = ['EfficientNet', 'EfficientNet+KNN', 'EfficientNet+SVC',\n",
        "             'EfficientNet+RF', 'EfficientNet+MLP']\n",
        "acc_list = [95, 93, 96, 88, 94]\n",
        "sen_list = [98, 96, 98, 94, 97]\n",
        "spe_list = [99, 99, 99, 98, 99]\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "\n",
        "plt.plot(name_list, acc_list)\n",
        "plt.plot(name_list, sen_list)\n",
        "plt.plot(name_list, spe_list)\n",
        "plt.ylim(85, 100)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "avVxJcDMUSn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelnames = (\n",
        "    'EfficientNet',\n",
        "    'EfficientNet+KNN',\n",
        "    'EfficientNet+SVC',\n",
        "    'EfficientNet+RF',\n",
        "    'EfficientNet+MLP'\n",
        ")\n",
        "\n",
        "tumor_acc = {\n",
        "    'Glioma':     (0.95, 0.93, 0.94, 0.84, 0.92),\n",
        "    'Meningioma': (0.92, 0.89, 0.93, 0.81, 0.89),\n",
        "    'NoTumor':    (0.98, 0.96, 0.99, 0.94, 0.97),\n",
        "    'Pituitary':  (0.96, 0.95, 0.98, 0.94, 0.97),\n",
        "}\n",
        "\n",
        "x = np.arange(len(modelnames))\n",
        "width = 0.2\n",
        "multiplier = 0\n",
        "\n",
        "fig, ax = plt.subplots(layout='constrained')\n",
        "\n",
        "for attribute, measurement in tumor_acc.items():\n",
        "    offset = width * multiplier\n",
        "    measurement = [m*100 for m in measurement]\n",
        "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
        "    ax.bar_label(rects, padding=3)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Tumor accuracies by Models')\n",
        "ax.set_xticks(x + width, modelnames)\n",
        "ax.legend(loc='upper left', ncols=4)\n",
        "ax.set_ylim(0, 150)\n",
        "\n",
        "plt.grid(linestyle = '--', linewidth = 0.5, zorder=1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dwoqjcPKX26K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}